"""Contains functions to get various prompt combinations"""
import os
import time
from typing import Literal
import dataclasses
import openai
import timeout_decorator  # type: ignore
import dotenv
import data
import nagini_client as nagini


def _get_user_message(key: str, example: str, with_errors: bool):
    """Get message for role user"""
    content_user = data.get_example(key, example, "unverified")
    if with_errors:
        content_user += f"\n{data.get_cached_result(key, example)}"
    return content_user

## TO-DO: Also extract a function to combine user provided program snippet and verification result
## and use it in _get_user_message and _extend_prompt

def get_few_shot_prompt(
    hold_out: str,
    key: str = "list",
    with_errors: bool = False,
    system_prompt: str = "system_prompt.txt",
) -> list[dict[str, str]]:
    """Returns a prompt with the solution to hold_out example held out"""
    examples = data.get_list_of_examples(key)
    messages = [{"role": "system", "content": data.get_system_prompt(system_prompt)}]
    for example in examples:
        if example != hold_out:
            messages.append(
                {
                    "role": "user",
                    "content": _get_user_message(key, example, with_errors),
                }
            )
            messages.append(
                {
                    "role": "assistant",
                    "content": data.get_example(key, example, "verified"),
                }
            )
    messages.append(
        {"role": "user", "content": _get_user_message(key, hold_out, with_errors)}
    )
    return messages


def _verify_program_snippet(
    key: str, program_snippet: str
) -> nagini.VerificationResult:
    """Expects: response contains a candidate program generated by assistant\n
    Sends the program to Nagini and returns the verification result"""
    program_file = _combine_method_with_declaration(key, program_snippet)
    result = nagini.verify(program_file)
    if result.line_no is not None:
        result.line_no = _get_relative_line_number(key, result.line_no)
    return result


def _combine_method_with_declaration(key: str, method_text: str) -> str:
    """Combines the method text with the declaration file and writes the output
    to a temporary file. Returns the (absolute) path to the temporary file."""
    declaration = data.get_declaration(key)
    with open(f"{data.DATA_ROOT}/tmp.py", "w", encoding="utf-8") as f:
        f.write(declaration + "\n" + method_text)
    # nagini expects the absolute path to the file
    return os.path.abspath(f"{data.DATA_ROOT}/tmp.py")


def _get_relative_line_number(key: str, line_no: str) -> str:
    """Returns the line number relative to the method"""
    declaration = data.get_declaration(key)
    line, column = line_no.split(".")
    rel_line = int(line) - len(declaration.split("\n"))
    return f"{rel_line}.{column}"


@timeout_decorator.timeout(60)
def _call_gpt_with_timeout(model: Literal["gpt-3.5-turbo", "gpt-4"], messages):
    """Timeout decorated function to call GPT API\n"""
    dotenv.load_dotenv()
    openai.api_key = os.getenv("GPT_SECRET_KEY")
    return openai.ChatCompletion.create(model=model, messages=messages)


@dataclasses.dataclass
class EvalResult:
    """Class to store the results of the evaluation"""

    results: dict[str, bool | Literal["Timeout"]] = dataclasses.field(
        default_factory=dict
    )
    verified_at: dict[str, tuple[int, int]] = dataclasses.field(default_factory=dict)


def _print_and_process_response(response: dict) -> str:
    """Print response from GPT and return the program snippet"""
    program_snippet = response["choices"][0]["message"]["content"]
    print("Generated program from GPT:")
    print(program_snippet)
    print("=====================================")
    return program_snippet


def run_eval(
    k=1,
    n=1,
    key="list",
    model: Literal["gpt-3.5-turbo", "gpt-4"] = "gpt-3.5-turbo",
    with_errors=False,
    system_prompt="system_prompt.txt",
) -> EvalResult:
    """Runs the evaluation for all examples in the list of examples for the given key\n"""
    examples = data.get_list_of_examples(key)
    # examples = ["prepend", "join_lists"]
    eval_result = EvalResult()
    for example in examples:
        for i in range(k):
            messages = get_few_shot_prompt(
                example, with_errors=with_errors, system_prompt=system_prompt
            )
            for j in range(n):
                print(
                    "Running example:",
                    example,
                    "; attempt:",
                    i + 1,
                    "; error depth:",
                    j + 1,
                )
                try:
                    response = _call_gpt_with_timeout(model, messages)
                except timeout_decorator.TimeoutError as e:
                    eval_result.results[example] = "Timeout"
                    print("Timeout error!", e)
                    continue
                program_snippet = _print_and_process_response(response)
                result = _verify_program_snippet(key, program_snippet)
                print("Verification result:\n", result, "\n\n")
                eval_result.results[example] = (
                    result.status == "Verification successful"
                )
                if eval_result.results[example]:
                    eval_result.verified_at[example] = (i + 1, j + 1)
                    break
                if n > 1:
                    _extend_prompt(messages, program_snippet, result)
                time.sleep(5)
            if eval_result.results[example]:
                break
    return eval_result


def _extend_prompt(
    messages: list[dict[str, str]],
    program_snippet: str,
    result: nagini.VerificationResult,
):
    """Extends the prompt with the program snippet and the verification result"""
    messages.append({"role": "assistant", "content": program_snippet})
    messages.append(
        {
            "role": "user",
            "content": program_snippet + "\n" + str(result),
        }
    )


def print_results(eval_result: EvalResult):
    """Prints the results of the evaluation"""
    results = eval_result.results
    verified_at = eval_result.verified_at
    examples = data.get_list_of_examples("list")
    print("Results:")
    for example in examples:
        print(
            example,
            ":",
            results[example],
            "verified at: k=",
            verified_at[example][0],
            "; n=",
            verified_at[example][1],
        )


# print(get_few_shot_prompt("prepend"))
# print(run_single("list", data.get_example("list", "join_lists", "unverified")))
