{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/omkar/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-west-1-929880127071'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='AmazonSageMaker-ExecutionRole-20240130T125539')['Role']['Arn']\n",
    "bucket = \"test-bucket\"\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_s3_uri = f\"s3://{bucket}/eval\"\n",
    "train_s3_uri = f\"s3://{bucket}/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Load the train and test split that will be used for evaluating the pretrained model, and then to finetune it.\n",
    "\n",
    "Train / test split plan: \n",
    "- for 'list': hold out 'drop_iter' completely, 'insert' partially (the first half)\n",
    "- for 'tree': hold out 'height' and 'insert' completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a704580e8b41e785cf197fdd07cfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "evalprompts = load_dataset(\"json\", data_files=\"evalprompts.jsonl\", split=\"train\")\n",
    "traindataset = load_dataset(\"json\", data_files=\"train_mar13.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600a2babfd6e4622b73d27fb6acb3fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f062cd604444bca12dba1bfde891ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a6fa4adaf645b9919350559ffab843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4611 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaldataset = load_dataset(\"json\", data_files=\"examples.jsonl\", split=\"train\")\n",
    "evaldataset.save_to_disk(eval_s3_uri)\n",
    "traindataset.save_to_disk(train_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the pretrained model\n",
    "Before fine-tuning, we will evaluate the pretrained model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import json\n",
    "\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'codellama/CodeLlama-7b-hf',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "    'HF_TASK':'text-generation'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "\twait=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evalresults_pretrained.txt\", 'w') as f:\n",
    "    for prompt in evalprompts:\n",
    "        output = predictor.predict(\n",
    "            {\n",
    "                \"inputs\": prompt[\"prompt\"],\n",
    "                \"parameters\": {\n",
    "                    \"do_sample\": True,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_new_tokens\": 256,\n",
    "                    \"return_full_text\": False,\n",
    "                    \"top_p\": 0.7,\n",
    "                    \"top_k\": 50,\n",
    "                    \"repetition_penalty\": 1,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        f.write(json.dumps({prompt['key']: output[0]['generated_text']}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_prepend --------------\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Postcondition of prepend might not hold. There might be insufficient permission to access is_list(Result()). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Postcondition of prepend might not hold. There might be insufficient permission to access is_list(Result()). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error\n",
      "list_append --------------\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "list_join_lists --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head1.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Returns the head of the list obtained by joining the two lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head1.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node])\n",
      "list_contains --------------\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given value.\"\"\"\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given value.\"\"\"\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next\n",
      "list_remove --------------\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def remove(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Removes the first node with the given value from the list.\"\"\"\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def remove(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Removes the first node with the given value from the list.\"\"\"\n",
      "\n",
      "list_merge --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head2.val. at line 11.7\n",
      "\n",
      "### Verified program:\n",
      "def merge(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Merges two sorted lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Ver\n",
      "list_insert --------------\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"Inserts the given node (given as a singleton list) into the sorted list.\"\"\"\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"In\n",
      "list_drop --------------\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\n",
      "    Permissions to the list until val node are leaked.\"\"\"\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops\n",
      "list_drop_iter --------------\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "### Unverified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\"\"\"\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access ptr.val. at line 5.11\n",
      "\n",
      "### Verified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\"\"\"\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is\n",
      "list_reverse --------------\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def reverseList(head: Node) -> Optional[Node]:\n",
      "    \"\"\"Reverses the list and returns the new head.\"\"\"\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3\n",
      "tree_val_head --------------\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "def val_at_head(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the value at the head of the tree rooted at node\"\"\"\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "def val_at_head(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the value at the head of the tree rooted at node\"\"\"\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "\n",
      "tree_height --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.16\n",
      "\n",
      "### Verified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.16\n",
      "\n",
      "### Verified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.\n",
      "tree_count --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count\n",
      "tree_sum --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "\n",
      "tree_insert --------------\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "### Verification error:\n",
      "tree_contains --------------\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(node: Optional[TreeNode], key: int) -> bool:\n",
      "    \"\"\"Returns whether the tree rooted at node contains the given key\"\"\"\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "##\n",
      "tree_inorder --------------\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.right. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access\n",
      "tree_min --------------\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node.left)\n",
      "    return m\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.right. at line 4.7\n",
      "\n",
      "### Verified program:\n",
      "def min_value(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the minimum value in the tree rooted at node\"\"\"\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node.left)\n",
      "    return m\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.left. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def min_value(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the minimum value in the tree rooted at node\"\"\"\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node\n",
      "tree_mirror --------------\n",
      "    if root is None:\n",
      "        return\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access root.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def mirror(root: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Mirrors the tree rooted at root\"\"\"\n",
      "    if root is None:\n",
      "        return\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "    Acc(root.left)\n",
      "    Acc(root.right)\n",
      "    Acc(root.left.left)\n",
      "    Acc(root.left.right)\n",
      "    Acc(root.right.left)\n",
      "    Acc(root.right.right)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access\n",
      "tree_subtree --------------\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line 6.8\n",
      "\n",
      "### Verified program:\n",
      "def subtree(root: Optional[TreeNode], key: int) -> Optional[TreeNode]:\n",
      "    \"\"\"Returns the subtree rooted at node with the given key if it exists, None otherwise\n",
      "    Permissions to the rest of the tree are leaked\"\"\"\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"evalresults_pretrained.txt\") as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        for k, v in d.items():\n",
    "            print(k, \"--------------\")\n",
    "            print(v)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the programs verify with the pretrained model. In most cases, it has just reproduced the unverified program from the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    \"py39\",\n",
    "    entry_point=\"sagemaker_train.py\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    # transformers_version='4.36',\n",
    "    # pytorch_version='2.1',\n",
    "    # py_version='py310',\n",
    "    image_uri=\"763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-training:1.13-transformers4.26-gpu-py39-cu117-ubuntu20.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-03-17-21-49-02-347\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({'train': train_s3_uri, 'test': eval_s3_uri}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-17 21:49:03 Starting - Starting the training job\n",
      "2024-03-17 21:49:03 Pending - Training job waiting for capacity...\n",
      "2024-03-17 21:49:24 Pending - Preparing the instances for training......\n",
      "2024-03-17 21:50:38 Downloading - Downloading the training image...............\n",
      "2024-03-17 21:52:59 Training - Training image download completed. Training in progress....bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-03-17 21:53:32,814 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-03-17 21:53:32,834 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-17 21:53:32,844 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-03-17 21:53:32,846 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-03-17 21:53:33,038 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.9 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.37.2\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 46.1 MB/s eta 0:00:00\n",
      "Collecting peft==0.8.2\n",
      "Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 38.0 MB/s eta 0:00:00\n",
      "Collecting trl==0.7.11\n",
      "Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 38.8 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes==0.42.0\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 23.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (5.4.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 20.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (1.23.5)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 97.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 61.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (1.13.1+cu117)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (5.9.4)\n",
      "Collecting accelerate\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.1/290.1 kB 54.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from trl==0.7.11->-r requirements.txt (line 3)) (2.9.0)\n",
      "Collecting tyro>=0.5.11\n",
      "Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 22.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 4)) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r requirements.txt (line 1)) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 171.9/171.9 kB 32.8 MB/s eta 0:00:00\n",
      "Collecting docstring-parser>=0.14.1\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Collecting shtab>=1.5.6\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.9/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (12.6.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.16.0)\n",
      "Installing collected packages: shtab, safetensors, fsspec, docstring-parser, tyro, huggingface-hub, bitsandbytes, tokenizers, accelerate, transformers, trl, peft\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.1.0\n",
      "Uninstalling fsspec-2023.1.0:\n",
      "Successfully uninstalled fsspec-2023.1.0\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.2\n",
      "Uninstalling tokenizers-0.13.2:\n",
      "Successfully uninstalled tokenizers-0.13.2\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Successfully installed accelerate-0.28.0 bitsandbytes-0.42.0 docstring-parser-0.16 fsspec-2024.3.0 huggingface-hub-0.21.4 peft-0.8.2 safetensors-0.4.2 shtab-1.7.1 tokenizers-0.15.2 transformers-4.37.2 trl-0.7.11 tyro-0.7.3\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-03-17 21:53:47,181 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-03-17 21:53:47,181 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-03-17 21:53:47,227 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-17 21:53:47,258 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-17 21:53:47,289 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-17 21:53:47,299 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-03-17-21-49-02-347\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-17-21-49-02-347/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sagemaker_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sagemaker_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=sagemaker_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=sagemaker_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-17-21-49-02-347/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-03-17-21-49-02-347\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-17-21-49-02-347/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_train.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 sagemaker_train.py\n",
      "[2024-03-17 21:53:49.148: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "2024-03-17 21:53:49,152 root         INFO     Using NamedTuple = typing._NamedTuple instead.\n",
      "2024-03-17 21:53:49,281 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [03:21<03:21, 201.09s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [04:35<00:00, 126.37s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [04:35<00:00, 137.58s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.18s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.01s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.24s/it]\n",
      "0%|          | 0/5 [00:00<?, ?ba/s]\n",
      "20%|██        | 1/5 [00:00<00:01,  2.82ba/s]\n",
      "40%|████      | 2/5 [00:00<00:01,  2.74ba/s]\n",
      "60%|██████    | 3/5 [00:01<00:00,  2.50ba/s]\n",
      "80%|████████  | 4/5 [00:01<00:00,  2.52ba/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.95ba/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.78ba/s]\n",
      "0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.07ba/s]\n",
      "/opt/conda/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "0%|          | 0/576 [00:00<?, ?it/s]\n",
      "[2024-03-17 21:58:50.897: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "INFO:root:Using NamedTuple = typing._NamedTuple instead.\n",
      "[2024-03-17 21:58:50.924 algo-1:65 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-03-17 21:58:50.950 algo-1:65 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2024-03-17 21:58:50.951 algo-1:65 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2024-03-17 21:58:50.951 algo-1:65 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2024-03-17 21:58:50.952 algo-1:65 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2024-03-17 21:58:50.952 algo-1:65 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "0%|          | 1/576 [00:50<8:04:43, 50.58s/it]\n",
      "0%|          | 2/576 [01:41<8:06:41, 50.87s/it]\n",
      "1%|          | 3/576 [02:29<7:53:26, 49.57s/it]\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the fine tuned model\n",
    "We have added a custom inference.py script to combine the model with the adapter. And archived it in model.tar.gz in code/inference.py as expected by the SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-16-13-38-364/output/model.tar.gz), script artifact (./scripts), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-22-18-35-112/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2024-02-19-22-18-35-112\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "model = huggingface_estimator.create_model(role=role, entry_point=\"inference.py\", source_dir=\"./scripts\")\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.g5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-06-23-57-59-373/output/model.tar.gz\",  # path to your trained sagemaker model\n",
    "   role=role,\n",
    "   transformers_version=\"4.37\", # transformers version used\n",
    "   pytorch_version=\"2.1\", # pytorch version used\n",
    "   py_version=\"py310\", # python version of the DLC\n",
    "   source_dir=\"./scripts_inference\",\n",
    "   entry_point=\"inference.py\"\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lseg_remove_last\n",
      "   Requires(lseg(first, last))\n",
      "    Ensures(lseg(first, Result()))\n",
      "    if first is None:\n",
      "        return last\n",
      "    if first is last:\n",
      "        return last\n",
      "    if Unfolding(lseg(first, last), first.next is last):\n",
      "        return first\n",
      "    Unfold(lseg(first, last))\n",
      "    rest = remove_last(first.next, last)\n",
      "    Fold(lseg(first, rest))\n",
      "    return rest\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = evalprompts[-8]\n",
    "print(prompt[\"key\"])\n",
    "\n",
    "output = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": prompt[\"prompt\"],\n",
    "        \"params\": {\n",
    "            \"max_new_tokens\": 256,\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            # \"top_p\": 0.7,\n",
    "            # \"top_k\": 50,\n",
    "            # \"repetition_penalty\": 1,            \n",
    "        },\n",
    "        \"decode_params\": {\n",
    "            \"skip_special_tokens\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-inference-2024-03-17-14-31-56-589'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, I am a 27 y/o\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"hello\",\n",
    "        \"params\": {\n",
    "            \"max_new_tokens\": 10,\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            # \"top_p\": 0.7,\n",
    "            # \"top_k\": 50,\n",
    "            # \"repetition_penalty\": 1,\n",
    "            'pad_token_id': None\n",
    "            \n",
    "        },\n",
    "        \"decode_params\": {\n",
    "            \"skip_special_tokens\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l4vp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
