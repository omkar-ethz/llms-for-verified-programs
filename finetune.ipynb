{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/omkar/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-west-1-929880127071'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='AmazonSageMaker-ExecutionRole-20240130T125539')['Role']['Arn']\n",
    "bucket = \"test-bucket\"\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_s3_uri = f\"s3://{bucket}/eval\"\n",
    "train_s3_uri = f\"s3://{bucket}/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Load the train and test split that will be used for evaluating the pretrained model, and then to finetune it.\n",
    "\n",
    "Train / test split plan: \n",
    "- for 'list': hold out 'drop_iter' completely, 'insert' partially (the first half)\n",
    "- for 'tree': hold out 'height' and 'insert' completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "evalprompts = load_dataset(\"json\", data_files=\"evalprompts.jsonl\", split=\"train\")\n",
    "traindataset = load_dataset(\"json\", data_files=\"train_master.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9541005c79e344d3924bc51c1992f746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3ac465ff8e4783b5e31e6df7e210b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaldataset = load_dataset(\"json\", data_files=\"examples.jsonl\", split=\"train\")\n",
    "evaldataset.save_to_disk(eval_s3_uri)\n",
    "traindataset.save_to_disk(train_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the pretrained model\n",
    "Before fine-tuning, we will evaluate the pretrained model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import json\n",
    "\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'codellama/CodeLlama-7b-hf',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "    'MAX_INPUT_LENGTH': json.dumps(8192), # Max length of input text\n",
    "  \t'MAX_TOTAL_TOKENS': json.dumps(9216), # Max length of the generation (including input text)\n",
    "    'MAX_BATCH_TOTAL_TOKENS': json.dumps(9216),\n",
    "    'MAX_BATCH_PREFILL_TOKENS': json.dumps(9216),\n",
    "    'HF_TASK':'text-generation'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "\twait=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['key', 'prompt'],\n",
       "    num_rows: 33\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalprompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evalresults_pretrained.txt\", 'w') as f:\n",
    "    for prompt in evalprompts:\n",
    "        output = predictor.predict(\n",
    "            {\n",
    "                \"inputs\": prompt[\"prompt\"],\n",
    "                \"parameters\": {\n",
    "                    \"do_sample\": True,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_new_tokens\": 256,\n",
    "                    \"return_full_text\": False,\n",
    "                    \"top_p\": 0.7,\n",
    "                    \"top_k\": 50,\n",
    "                    \"repetition_penalty\": 1,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        f.write(json.dumps({prompt['key']: output[0]['generated_text']}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_prepend --------------\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Invariant of prepend might not hold. There might be insufficient permission to access is_list(head). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Postcondition of prepend might not hold. There might be insufficient permission to access is_list(head). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error\n",
      "list_append --------------\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 11.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 11.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(\n",
      "list_join_lists --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head2.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Returns the head of the list obtained by joining the two lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head1.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node])\n",
      "list_contains --------------\n",
      "    Requires(is_list(head))\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 4.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given value.\"\"\"\n",
      "    Requires(is_list(head))\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given\n",
      "list_remove --------------\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "### Explanation:\n",
      "The program fails to verify because the head.val access in the if statement is not guarded by the head is not None check.\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.10\n",
      "\n",
      "### Verified program:\n",
      "def remove(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Removes the first node with the given value from the list.\"\"\"\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "### Explanation:\n",
      "The program fails to verify because the head.next access in the if statement is not guarded by the head is not None check.\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional\n",
      "list_merge --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head2.val. at line 7.7\n",
      "\n",
      "### Verified program:\n",
      "def merge(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Merges two sorted lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Verification\n",
      "list_insert --------------\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"Inserts the given node (given as a singleton list) into the sorted list.\"\"\"\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"In\n",
      "list_drop --------------\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\n",
      "    Permissions to the list until val node are leaked.\"\"\"\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"D\n",
      "list_drop_iter --------------\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access ptr.next. at line 5.11\n",
      "\n",
      "### Verified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\"\"\"\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access ptr.val. at line 5.11\n",
      "\n",
      "### Verified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until\n",
      "list_reverse --------------\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def reverseList(head: Node) -> Optional[Node]:\n",
      "    \"\"\"Reverses the list and returns the new head.\"\"\"\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3\n",
      "tree_val_head --------------\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Unverified program:\n",
      "def is_empty(node: TreeNode) -> bool:\n",
      "    \"\"\"Returns True iff the tree rooted at node is empty\"\"\"\n",
      "    return node.left is None and node.right is None\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "def is_empty(node: TreeNode) -> bool:\n",
      "    \"\"\"Returns True iff the tree rooted at node is empty\"\"\"\n",
      "    Requires(tree(node))\n",
      "    return node.left is None and node.right is None\n",
      "\n",
      "\n",
      "### Unverified program:\n",
      "def successor(node: TreeNode) -> TreeNode:\n",
      "    \"\"\"Returns the successor of node, or None if node is the last node\"\"\"\n",
      "    if node.right is not None:\n",
      "        return successor(node.right)\n",
      "    else:\n",
      "        p = node.parent\n",
      "        while p is not None and node is\n",
      "tree_height --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "### Explanation:\n",
      "We can see that the verification error is that we don't have a Requires(is_list(head)) on line 5.16. We can fix this by adding a Requires(is_list(node)) annotation on line 4.10.\n",
      "\n",
      "### Unverified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.16\n",
      "\n",
      "### Verified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\n",
      "tree_count --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count\n",
      "tree_sum --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return \n",
      "tree_insert --------------\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "\n",
      "### Verification\n",
      "tree_contains --------------\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(node: Optional[TreeNode], key: int) -> bool:\n",
      "    \"\"\"Returns whether the tree rooted at node contains the given key\"\"\"\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "##\n",
      "tree_inorder --------------\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Explanation:\n",
      "We need to add a predicate to inorder to ensure that the node is not None.\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Explanation:\n",
      "We need to add a predicate to inorder to ensure that the node is not None.\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "\n",
      "tree_min --------------\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node.left)\n",
      "    return m\n",
      "\n",
      "### Explanation:\n",
      "Acc(node.left) is not a valid assertion.\n",
      "\n",
      "### Unverified program:\n",
      "def tree_search(node: TreeNode, k: int) -> bool:\n",
      "    \"\"\"Returns True if the key k is in the tree rooted at node\"\"\"\n",
      "    if node.key == k:\n",
      "        return True\n",
      "    if node.left is None:\n",
      "        return False\n",
      "    if k < node.key:\n",
      "        return tree_search(node.left, k)\n",
      "    else:\n",
      "        return tree_search(node.right, k)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.left. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def tree_search(node: TreeNode, k: int) -> bool:\n",
      "    \"\"\"Returns True if the key k is in the tree rooted at node\"\"\"\n",
      "    if node\n",
      "tree_mirror --------------\n",
      "    if root is None:\n",
      "        return\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access root.right. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def mirror(root: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Mirrors the tree rooted at root\"\"\"\n",
      "    if root is None:\n",
      "        return\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access root.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def mirror(root: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Mirrors the tree rooted at root\"\"\"\n",
      "    if root is None:\n",
      "        return\n",
      "\n",
      "tree_subtree --------------\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line 6.8\n",
      "\n",
      "### Verified program:\n",
      "def subtree(root: Optional[TreeNode], key: int) -> Optional[TreeNode]:\n",
      "    \"\"\"Returns the subtree rooted at node with the given key if it exists, None otherwise\n",
      "    Permissions to the rest of the tree are leaked\"\"\"\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line\n",
      "lseg_lemma_append --------------\n",
      "    if a is b:\n",
      "        return\n",
      "    lemma_append(a.next, b)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access a.next. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def lemma_append(a: Optional[Node], b: Optional[Node]) -> None:\n",
      "    \"\"\"Append two list segments.\"\"\"\n",
      "    if a is b:\n",
      "        return\n",
      "    lemma_append(a.next, b)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access a.next. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def lemma_append(a: Optional[Node], b: Optional[Node]) -> None:\n",
      "    \"\"\"Append two list segments.\"\"\"\n",
      "    if a is b:\n",
      "        return\n",
      "    lemma_append(a.next, b)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access a.next. at line 5.4\n",
      "\n",
      "###\n",
      "lseg_lemma_extend --------------\n",
      "    if a is b:\n",
      "        last = b.next\n",
      "        return last\n",
      "    last = lemma_extend(a.next, b)\n",
      "    return last\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access b.next. at line 4.8\n",
      "\n",
      "### Verified program:\n",
      "def lemma_extend(a: Optional[Node], b: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Extend a list segment by one element and return the new last\"\"\"\n",
      "    if a is b:\n",
      "        last = b.next\n",
      "        return last\n",
      "    last = lemma_extend(a.next, b)\n",
      "    return last\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access b.next. at line 4.8\n",
      "\n",
      "### Verified program:\n",
      "def lemma_extend(a: Optional[Node], b: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Extend a list segment by one element and return the new last\"\"\"\n",
      "    if a is b:\n",
      "        last =\n",
      "lseg_lemma_assoc --------------\n",
      "    if b is c:\n",
      "        return\n",
      "    b_new = lemma_extend(a, b)\n",
      "    lemma_assoc(a, b_new, c)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: The postcondition of method lemma_assoc might not hold. The postcondition of method lemma_extend might not hold. There might be insufficient permission to access lseg(a, b_new). at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def lemma_assoc(a: Optional[Node], b: Optional[Node], c: Optional[Node]) -> None:\n",
      "    \"\"\"Associativity of list segment.\"\"\"\n",
      "    if b is c:\n",
      "        return\n",
      "    b_new = lemma_extend(a, b)\n",
      "    lemma_assoc(a, b_new, c)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: The postcondition of method lemma_extend might not hold. There might be insufficient permission to access lseg(a, b_new). at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def lemma_assoc(a: Optional[Node], b:\n",
      "lseg_prepend --------------\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Unverified program:\n",
      "def prepend(head: Optional[Node], val: int) -> Node:\n",
      "    \"\"\"Prepend a new node with value val to the list.\"\"\"\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification successful\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Optional[Node], val: int) -> Node:\n",
      "    \"\"\"Prepend a new node with value val to the list.\"\"\"\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Unverified program:\n",
      "def prepend(head: Optional[Node], val: int) -> Node:\n",
      "    \"\"\"Prepend a new node with value val to the list.\"\"\"\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification successful\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Optional[Node], val: int) -> Node:\n",
      "    \"\"\"Prepend a new node with value val to the list.\"\n",
      "lseg_remove_first --------------\n",
      "    if first is last:\n",
      "        return last\n",
      "    rest = first.next\n",
      "    return rest\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access first.next. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def remove_first(first: Node, last: Node) -> Optional[Node]:\n",
      "    \"\"\"Remove the first node from the list.\"\"\"\n",
      "    if first is last:\n",
      "        return last\n",
      "    rest = first.next\n",
      "    return rest\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access first.next. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def remove_first(first: Node, last: Node) -> Optional[Node]:\n",
      "    \"\"\"Remove the first node from the list.\"\"\"\n",
      "    if first is last:\n",
      "        return last\n",
      "    rest = first.next\n",
      "    return rest\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access first.next. at line 5.4\n",
      "\n",
      "\n",
      "lseg_remove_last --------------\n",
      "    if first is None:\n",
      "        return last\n",
      "    if first is last:\n",
      "        return last\n",
      "    if first.next is last:\n",
      "        return first\n",
      "    rest = remove_last(first.next, last)\n",
      "    return rest\n",
      "\n",
      "### Explanation:\n",
      "The verifier found that the condition first.next is last might fail. To fix this, we added the precondition first is not last.\n",
      "\n",
      "### Unverified program:\n",
      "def remove_last(first: Optional[Node], last: Node) -> Optional[Node]:\n",
      "    \"\"\"Remove the last node from the list and returns the new last\"\"\"\n",
      "    if first is None:\n",
      "        return last\n",
      "    if first is last:\n",
      "        return last\n",
      "    if first.next is last:\n",
      "        return first\n",
      "    rest = remove_last(first.next, last)\n",
      "    return rest\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access first.next. at line 7.7\n",
      "\n",
      "### Verified program:\n",
      "def remove_last(first: Optional[Node], last: Node) -> Optional[Node\n",
      "lseg_contains --------------\n",
      "    if first is None:\n",
      "        return False\n",
      "    if first is last:\n",
      "        return False\n",
      "    if first.val == val:\n",
      "        return True\n",
      "    result = contains(first.next, last, val)\n",
      "    return result\n",
      "\n",
      "### Unverified program:\n",
      "def remove(first: Optional[Node], last: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Remove the first node with value val from the list.\n",
      "\n",
      "    Return the new first node of the list.\n",
      "    \"\"\"\n",
      "    if first is None:\n",
      "        return None\n",
      "    if first.val == val:\n",
      "        return first.next\n",
      "    first.next = remove(first.next, last, val)\n",
      "    return first\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access first.next. at line 7.7\n",
      "\n",
      "### Verified program:\n",
      "def remove(first: Optional[Node], last: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Remove the first node with value val from the list.\n",
      "\n",
      "    Return the new first node of the\n",
      "lseg_contains_iter --------------\n",
      "    ptr = first  # type: Optional[Node]\n",
      "    result = False\n",
      "    while ptr is not None and ptr is not last:\n",
      "        if ptr.val == val:\n",
      "            result = True\n",
      "            break\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        lemma_extend(first, tmp)\n",
      "    lemma_assoc(first, ptr, last)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access ptr.val. at line 6.11\n",
      "\n",
      "### Verified program:\n",
      "def contains_iter(first: Node, last: Optional[Node], val: int) -> bool:\n",
      "    \"\"\"Check if the list contains a node with value val.\"\"\"\n",
      "    ptr = first  # type: Optional[Node]\n",
      "    result = False\n",
      "    while ptr is not None and ptr is not last:\n",
      "        if ptr.val == val:\n",
      "            result = True\n",
      "            break\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        lemma_extend(first, tmp)\n",
      "    lemma_assoc(first, ptr, last)\n",
      "    return result\n",
      "lseg_insert --------------\n",
      "    if pos == 0:\n",
      "        return prepend(head, val)\n",
      "    if head is None:\n",
      "        return None\n",
      "    head.next = insert(head.next, val, pos - 1)\n",
      "    return head\n",
      "\n",
      "### Explanation:\n",
      "We need to add a Requires(lseg(head, None)) to the insert method.\n",
      "\n",
      "### Unverified program:\n",
      "def delete(head: Optional[Node], pos: int) -> Optional[Node]:\n",
      "    \"\"\"Delete the node at position pos in the list.\"\"\"\n",
      "    if pos == 0:\n",
      "        return head.next\n",
      "    if head is None:\n",
      "        return None\n",
      "    head.next = delete(head.next, pos - 1)\n",
      "    return head\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: The precondition of method delete might not hold. There might be insufficient permission to access lseg(head, None). at line 4.15\n",
      "\n",
      "### Verified program:\n",
      "def delete(head: Optional[Node], pos: int) -> Optional[Node]:\n",
      "    \"\"\"Delete the node at position pos in the list.\"\"\"\n",
      "lseg_insert_iter --------------\n",
      "    if pos == 0:\n",
      "        return prepend(head, val)\n",
      "    if head is None:\n",
      "        return None\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while pos > 1 and ptr is not None:\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        lemma_extend(head, tmp)\n",
      "        pos -= 1\n",
      "    if ptr is None:\n",
      "        return head\n",
      "    n = Node(val, ptr.next)\n",
      "    ptr.next = n\n",
      "    lemma_extend(head, ptr)\n",
      "    lemma_append(head, n)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: The postcondition of method insert_iter might not hold. There might be insufficient permission to access lseg(head, None). at line 4.15\n",
      "\n",
      "### Verified program:\n",
      "def insert_iter(head: Optional[Node], val: int, pos: int) -> Optional[Node]:\n",
      "    \"\"\"Insert a new node with value val at position pos in the list.\"\"\"\n",
      "    if pos == 0:\n",
      "        return prepend(head, val)\n",
      "   \n",
      "lseg_append --------------\n",
      "    n = Node(val)\n",
      "    if head is None:\n",
      "        return n\n",
      "    ptr = head  # type: Node\n",
      "    while ptr.next is not None:\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        lemma_extend(head, tmp)\n",
      "    ptr.next = n\n",
      "    lemma_append(head, ptr)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Unverified program:\n",
      "def delete(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Delete the first node with value val in the list.\"\"\"\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    ptr = head  # type: Node\n",
      "    while ptr.next is not None:\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        lemma_extend(head, tmp)\n",
      "    if ptr.val == val:\n",
      "        return head\n",
      "    lemma_delete(head, ptr)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: While statement might fail. There might be insufficient permission to access ptr.next. at line 7\n",
      "lseg_index_of --------------\n",
      "    ptr = first  # type: Optional[Node]\n",
      "    index = 0\n",
      "    while ptr is not None and ptr is not last:\n",
      "        if ptr.val == val:\n",
      "            lemma_assoc(first, ptr, last)\n",
      "            return index\n",
      "        tmp = ptr\n",
      "        ptr = ptr.next\n",
      "        index += 1\n",
      "    return -1\n",
      "\n",
      "### Explanation:\n",
      "You must add a Requires(Implies(n is not None, predicate(n))) annotation to the index_of function.\n",
      "\n",
      "### Hint:\n",
      "\n",
      "If you are stuck, you can take a look at the annotated code in the next exercise.\n",
      "\n",
      "### Hint:\n",
      "\n",
      "You can use the `lemma_assoc` function from the previous exercise to annotate the function.\n",
      "\n",
      "### Hint:\n",
      "\n",
      "The lemma_assoc function is defined as follows:\n",
      "\n",
      "@Predicate\n",
      "def lemma_assoc(first: Node, ptr: Node, last: Optional[Node]) -> bool:\n",
      "    return Implies(\n",
      "        first is ptr,\n",
      "        Acc(first.val) and Acc(first.next) and lseg(first.next,\n",
      "lseg_reverse --------------\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None  # type: Optional[Node]\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def reverse(head: Node) -> Optional[Node]:\n",
      "    \"\"\"Reverse the list segment.\"\"\"\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None  # type: Optional[Node]\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"evalresults_pretrained.txt\") as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        for k, v in d.items():\n",
    "            print(k, \"--------------\")\n",
    "            print(v)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the programs verify with the pretrained model. In most cases, it has just reproduced the unverified program from the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    \"py39\",\n",
    "    entry_point=\"sagemaker_train.py\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    # transformers_version='4.36',\n",
    "    # pytorch_version='2.1',\n",
    "    # py_version='py310',\n",
    "    checkpoint_s3_uri=f\"s3://{bucket}/checkpoints-master\",\n",
    "    image_uri=\"763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-training:1.13-transformers4.26-gpu-py39-cu117-ubuntu20.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-03-20-07-01-10-407\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({'train': train_s3_uri, 'test': eval_s3_uri}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 07:01:13 Starting - Starting the training job\n",
      "2024-03-20 07:01:13 Pending - Training job waiting for capacity...\n",
      "2024-03-20 07:01:36 Pending - Preparing the instances for training......\n",
      "2024-03-20 07:02:37 Downloading - Downloading input data...\n",
      "2024-03-20 07:02:57 Downloading - Downloading the training image..................\n",
      "2024-03-20 07:06:22 Training - Training image download completed. Training in progress.....bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-03-20 07:06:49,709 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-03-20 07:06:49,729 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-20 07:06:49,739 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-03-20 07:06:49,740 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-03-20 07:06:49,923 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.9 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.37.2\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 90.0 MB/s eta 0:00:00\n",
      "Collecting peft==0.8.2\n",
      "Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 34.6 MB/s eta 0:00:00\n",
      "Collecting trl==0.7.11\n",
      "Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 32.7 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes==0.42.0\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 23.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (23.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 93.5 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 103.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 57.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (3.9.0)\n",
      "Collecting accelerate\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.1/290.1 kB 45.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (1.13.1+cu117)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (5.9.4)\n",
      "Collecting tyro>=0.5.11\n",
      "Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 20.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from trl==0.7.11->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 4)) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r requirements.txt (line 1)) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 36.6 MB/s eta 0:00:00\n",
      "Collecting shtab>=1.5.6\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.9/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (12.6.0)\n",
      "Collecting docstring-parser>=0.14.1\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.16.0)\n",
      "Installing collected packages: shtab, safetensors, fsspec, docstring-parser, tyro, huggingface-hub, bitsandbytes, tokenizers, accelerate, transformers, trl, peft\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.1.0\n",
      "Uninstalling fsspec-2023.1.0:\n",
      "Successfully uninstalled fsspec-2023.1.0\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.2\n",
      "Uninstalling tokenizers-0.13.2:\n",
      "Successfully uninstalled tokenizers-0.13.2\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Successfully installed accelerate-0.28.0 bitsandbytes-0.42.0 docstring-parser-0.16 fsspec-2024.3.1 huggingface-hub-0.21.4 peft-0.8.2 safetensors-0.4.2 shtab-1.7.1 tokenizers-0.15.2 transformers-4.37.2 trl-0.7.11 tyro-0.7.3\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-03-20 07:07:03,608 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-03-20 07:07:03,608 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-03-20 07:07:03,648 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-20 07:07:03,680 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-20 07:07:03,711 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-20 07:07:03,723 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-03-20-07-01-10-407\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-20-07-01-10-407/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sagemaker_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sagemaker_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=sagemaker_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=sagemaker_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-20-07-01-10-407/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-03-20-07-01-10-407\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-20-07-01-10-407/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_train.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 sagemaker_train.py\n",
      "[2024-03-20 07:07:05.703: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "2024-03-20 07:07:05,707 root         INFO     Using NamedTuple = typing._NamedTuple instead.\n",
      "2024-03-20 07:07:05,837 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [01:16<01:16, 76.44s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [01:39<00:00, 45.13s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [01:39<00:00, 49.83s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.60s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.55s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.91s/it]\n",
      "0%|          | 0/12 [00:00<?, ?ba/s]\n",
      "8%|▊         | 1/12 [00:00<00:03,  2.94ba/s]\n",
      "17%|█▋        | 2/12 [00:00<00:03,  2.95ba/s]\n",
      "25%|██▌       | 3/12 [00:00<00:02,  3.04ba/s]\n",
      "33%|███▎      | 4/12 [00:01<00:02,  3.00ba/s]\n",
      "42%|████▏     | 5/12 [00:01<00:02,  2.89ba/s]\n",
      "50%|█████     | 6/12 [00:02<00:02,  2.69ba/s]\n",
      "58%|█████▊    | 7/12 [00:02<00:01,  2.59ba/s]\n",
      "67%|██████▋   | 8/12 [00:02<00:01,  2.62ba/s]\n",
      "75%|███████▌  | 9/12 [00:03<00:01,  2.57ba/s]\n",
      "83%|████████▎ | 10/12 [00:03<00:00,  2.43ba/s]\n",
      "92%|█████████▏| 11/12 [00:04<00:00,  2.47ba/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  3.03ba/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.77ba/s]\n",
      "/opt/conda/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "0%|          | 0/1068 [00:00<?, ?it/s]\n",
      "[2024-03-20 07:09:15.819: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "INFO:root:Using NamedTuple = typing._NamedTuple instead.\n",
      "[2024-03-20 07:09:15.847 algo-1:65 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-03-20 07:09:15.874 algo-1:65 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2024-03-20 07:09:15.874 algo-1:65 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2024-03-20 07:09:15.874 algo-1:65 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2024-03-20 07:09:15.875 algo-1:65 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "0%|          | 1/1068 [00:50<14:53:12, 50.23s/it]\n",
      "0%|          | 2/1068 [01:40<14:54:15, 50.33s/it]\n",
      "0%|          | 3/1068 [02:29<14:41:51, 49.68s/it]\n",
      "0%|          | 4/1068 [03:20<14:50:59, 50.24s/it]\n",
      "0%|          | 5/1068 [04:11<14:50:52, 50.28s/it]\n",
      "1%|          | 6/1068 [05:03<15:02:25, 50.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhuggingface_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/estimator.py:1523\u001b[0m, in \u001b[0;36mEstimatorBase.logs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display the logs for Estimator's training job.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded based\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m    on which instance the log entry is from.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1523\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/session.py:5568\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5548\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5549\u001b[0m \n\u001b[1;32m   5550\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/session.py:7661\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   7659\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 7661\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   7664\u001b[0m     state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the fine tuned model\n",
    "We have added a custom inference.py script to combine the model with the adapter. And archived it in model.tar.gz in code/inference.py as expected by the SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-16-13-38-364/output/model.tar.gz), script artifact (./scripts), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-22-18-35-112/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2024-02-19-22-18-35-112\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "model = huggingface_estimator.create_model(role=role, entry_point=\"inference.py\", source_dir=\"./scripts\")\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.g5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-20-07-01-10-407/output/model.tar.gz\",  # path to your trained sagemaker model\n",
    "   role=role,\n",
    "   transformers_version=\"4.37\", # transformers version used\n",
    "   pytorch_version=\"2.1\", # pytorch version used\n",
    "   py_version=\"py310\", # python version of the DLC\n",
    "   source_dir=\"./scripts_inference\",\n",
    "   entry_point=\"inference.py\"\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lseg_remove_last\n",
      "   Requires(lseg(first, last))\n",
      "    Ensures(lseg(first, Result()))\n",
      "    if first is None:\n",
      "        return last\n",
      "    if first is last:\n",
      "        return last\n",
      "    if Unfolding(lseg(first, last), first.next is last):\n",
      "        return first\n",
      "    Unfold(lseg(first, last))\n",
      "    rest = remove_last(first.next, last)\n",
      "    Fold(lseg(first, rest))\n",
      "    return rest\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = evalprompts[-8]\n",
    "print(prompt[\"key\"])\n",
    "\n",
    "output = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": prompt[\"prompt\"],\n",
    "        \"params\": {\n",
    "            \"max_new_tokens\": 256,\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            # \"top_p\": 0.7,\n",
    "            # \"top_k\": 50,\n",
    "            # \"repetition_penalty\": 1,            \n",
    "        },\n",
    "        \"decode_params\": {\n",
    "            \"skip_special_tokens\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-inference-2024-03-17-14-31-56-589'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, I am a 27 y/o\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"hello\",\n",
    "        \"params\": {\n",
    "            \"max_new_tokens\": 10,\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            # \"top_p\": 0.7,\n",
    "            # \"top_k\": 50,\n",
    "            # \"repetition_penalty\": 1,\n",
    "            'pad_token_id': None\n",
    "            \n",
    "        },\n",
    "        \"decode_params\": {\n",
    "            \"skip_special_tokens\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l4vp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
