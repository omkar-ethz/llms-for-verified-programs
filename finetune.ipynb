{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-west-1-929880127071'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='AmazonSageMaker-ExecutionRole-20240130T125539')['Role']['Arn']\n",
    "bucket = \"test-bucket\"\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_s3_uri = f\"s3://{bucket}/eval\"\n",
    "train_s3_uri = f\"s3://{bucket}/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Load the train and test split that will be used for evaluating the pretrained model, and then to finetune it.\n",
    "\n",
    "Train / test split plan: \n",
    "- for 'list': hold out 'drop_iter' completely, 'insert' partially (the first half)\n",
    "- for 'tree': hold out 'height' and 'insert' completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626c944466e840efb1db131557ab9459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "evalprompts = load_dataset(\"json\", data_files=\"evalprompts.jsonl\", split=\"train\")\n",
    "traindataset = load_dataset(\"json\", data_files=\"train_mar6.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c126fc07544ccea522b90b79fa5de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f769a9619443a8d5160ff7679a794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaldataset = load_dataset(\"json\", data_files=\"examples.jsonl\", split=\"train\")\n",
    "evaldataset.save_to_disk(eval_s3_uri)\n",
    "traindataset.save_to_disk(train_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda3578f071c4495b24c1cdaccc1b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36033"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalprompts.to_json(f\"{eval_s3_uri}/evalprompts.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the pretrained model\n",
    "Before fine-tuning, we will evaluate the pretrained model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import json\n",
    "\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'codellama/CodeLlama-7b-hf',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "    'HF_TASK':'text-generation'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "\twait=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evalresults_pretrained.txt\", 'w') as f:\n",
    "    for prompt in evalprompts:\n",
    "        output = predictor.predict(\n",
    "            {\n",
    "                \"inputs\": prompt[\"prompt\"],\n",
    "                \"parameters\": {\n",
    "                    \"do_sample\": True,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_new_tokens\": 256,\n",
    "                    \"return_full_text\": False,\n",
    "                    \"top_p\": 0.7,\n",
    "                    \"top_k\": 50,\n",
    "                    \"repetition_penalty\": 1,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        f.write(json.dumps({prompt['key']: output[0]['generated_text']}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_prepend --------------\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Postcondition of prepend might not hold. There might be insufficient permission to access is_list(Result()). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Postcondition of prepend might not hold. There might be insufficient permission to access is_list(Result()). at line 3.12\n",
      "\n",
      "### Verified program:\n",
      "def prepend(head: Node, val: int) -> Node:\n",
      "    \"\"\"Prepends a new node with the given value to the list.\"\"\"\n",
      "    Ensures(is_list(Result()))\n",
      "    n = Node(val, head)\n",
      "    return n\n",
      "\n",
      "\n",
      "### Verification error\n",
      "list_append --------------\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "        head.next = n\n",
      "    else:\n",
      "        append(head.next, val)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def append(head: Node, val: int) -> None:\n",
      "    \"\"\"Appends a new node with the given value to the end of the list.\"\"\"\n",
      "    if head.next is None:\n",
      "        n = Node(val)\n",
      "list_join_lists --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head1.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Returns the head of the list obtained by joining the two lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    head1.next = join_lists(head1.next, head2)\n",
      "    return head1\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access head1.next. at line 7.17\n",
      "\n",
      "### Verified program:\n",
      "def join_lists(head1: Optional[Node], head2: Optional[Node])\n",
      "list_contains --------------\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given value.\"\"\"\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next is None:\n",
      "        return False\n",
      "    result = contains(head.next, val)\n",
      "    return result\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(head: Node, val: int) -> bool:\n",
      "    \"\"\"Returns True if the list contains the given value.\"\"\"\n",
      "    if head.val == val:\n",
      "        return True\n",
      "    if head.next\n",
      "list_remove --------------\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def remove(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Removes the first node with the given value from the list.\"\"\"\n",
      "    if head.val == val:\n",
      "        return head.next\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    head.next = remove(head.next, val)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.val. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def remove(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Removes the first node with the given value from the list.\"\"\"\n",
      "\n",
      "list_merge --------------\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head2.val. at line 11.7\n",
      "\n",
      "### Verified program:\n",
      "def merge(head1: Optional[Node], head2: Optional[Node]) -> Optional[Node]:\n",
      "    \"\"\"Merges two sorted lists.\"\"\"\n",
      "    if head1 is None:\n",
      "        return head2\n",
      "    if head2 is None:\n",
      "        return head1\n",
      "    if head1.val < head2.val:\n",
      "        head1.next = merge(head1.next, head2)\n",
      "        return head1\n",
      "    head2.next = merge(head1, head2.next)\n",
      "    return head2\n",
      "\n",
      "### Verification error:\n",
      "Ver\n",
      "list_insert --------------\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"Inserts the given node (given as a singleton list) into the sorted list.\"\"\"\n",
      "    if head is None:\n",
      "        return node\n",
      "    if node.val < head.val:\n",
      "        node.next = head\n",
      "        return node\n",
      "    head.next = insert(node, head.next)\n",
      "    return head\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.val. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: Node, head: Optional[Node]) -> Node:\n",
      "    \"\"\"In\n",
      "list_drop --------------\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\n",
      "    Permissions to the list until val node are leaked.\"\"\"\n",
      "    if head is None:\n",
      "        return None\n",
      "    if head.val == val:\n",
      "        return head\n",
      "    result = drop(head.next, val)\n",
      "    return result\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def drop(head: Optional[Node], val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops\n",
      "list_drop_iter --------------\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "### Unverified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\"\"\"\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is not None:\n",
      "        if ptr.val == val:\n",
      "            return ptr\n",
      "        ptr = ptr.next\n",
      "    return None\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access ptr.val. at line 5.11\n",
      "\n",
      "### Verified program:\n",
      "def drop_iter(head: Node, val: int) -> Optional[Node]:\n",
      "    \"\"\"Drops nodes until val is found and returns the list starting at val node, or None if not found.\"\"\"\n",
      "    ptr = head  # type: Optional[Node]\n",
      "    while ptr is\n",
      "list_reverse --------------\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def reverseList(head: Node) -> Optional[Node]:\n",
      "    \"\"\"Reverses the list and returns the new head.\"\"\"\n",
      "    if head.next is None:\n",
      "        return head\n",
      "    prev = None # type: Optional[Node]\n",
      "    ptr = head # type: Optional[Node]\n",
      "    while ptr != None:\n",
      "        tmp = ptr.next\n",
      "        ptr.next = prev\n",
      "        prev = ptr\n",
      "        ptr = tmp\n",
      "    return prev\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access head.next. at line 3\n",
      "tree_val_head --------------\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "def val_at_head(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the value at the head of the tree rooted at node\"\"\"\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "def val_at_head(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the value at the head of the tree rooted at node\"\"\"\n",
      "    Requires(tree(node))\n",
      "    return node.key\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access node.left. at line 3.4\n",
      "\n",
      "### Verified program:\n",
      "\n",
      "tree_height --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.16\n",
      "\n",
      "### Verified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.right))\n",
      "    return h\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.16\n",
      "\n",
      "### Verified program:\n",
      "def height(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the height of the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    h = 1 + max(height(node.left), height(node.\n",
      "tree_count --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count(node.right)\n",
      "    return c\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.12\n",
      "\n",
      "### Verified program:\n",
      "def count(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the number of nodes in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    c = 1 + count(node.left) + count\n",
      "tree_sum --------------\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "    s = node.key + sum_nodes(node.left) + sum_nodes(node.right)\n",
      "    return s\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.19\n",
      "\n",
      "### Verified program:\n",
      "def sum_nodes(node: Optional[TreeNode]) -> int:\n",
      "    \"\"\"Returns the sum of the keys in the tree rooted at node\"\"\"\n",
      "    if node is None:\n",
      "        return 0\n",
      "\n",
      "tree_insert --------------\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    if node.left is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.left = new_node\n",
      "    else:\n",
      "        insert(node.left, key)\n",
      "    if node.right is None:\n",
      "        new_node = TreeNode(key)\n",
      "        node.right = new_node\n",
      "    else:\n",
      "        insert(node.right, key)\n",
      "\n",
      "### Verification error:\n",
      "tree_contains --------------\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "### Verified program:\n",
      "def contains(node: Optional[TreeNode], key: int) -> bool:\n",
      "    \"\"\"Returns whether the tree rooted at node contains the given key\"\"\"\n",
      "    if node is None:\n",
      "        return False\n",
      "    if node.key == key:\n",
      "        return True\n",
      "    if key < node.key:\n",
      "        result = contains(node.left, key)\n",
      "    else:\n",
      "        result = contains(node.right, key)\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 5.7\n",
      "\n",
      "##\n",
      "tree_inorder --------------\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.right. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access node.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def inorder(node: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Inorder traversal of a binary tree.\"\"\"\n",
      "    if node is None:\n",
      "        return\n",
      "    inorder(node.left)\n",
      "    inorder(node.right)\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Method call might fail. There might be insufficient permission to access\n",
      "tree_min --------------\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node.left)\n",
      "    return m\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.right. at line 4.7\n",
      "\n",
      "### Verified program:\n",
      "def min_value(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the minimum value in the tree rooted at node\"\"\"\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node.left)\n",
      "    return m\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.left. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def min_value(node: TreeNode) -> int:\n",
      "    \"\"\"Returns the minimum value in the tree rooted at node\"\"\"\n",
      "    if node.left is None:\n",
      "        m = node.key\n",
      "        return m\n",
      "    m = min_value(node\n",
      "tree_mirror --------------\n",
      "    if root is None:\n",
      "        return\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access root.left. at line 5.4\n",
      "\n",
      "### Verified program:\n",
      "def mirror(root: Optional[TreeNode]) -> None:\n",
      "    \"\"\"Mirrors the tree rooted at root\"\"\"\n",
      "    if root is None:\n",
      "        return\n",
      "    mirror(root.left)\n",
      "    mirror(root.right)\n",
      "    temp = root.left\n",
      "    root.left = root.right\n",
      "    root.right = temp\n",
      "    Acc(root.left)\n",
      "    Acc(root.right)\n",
      "    Acc(root.left.left)\n",
      "    Acc(root.left.right)\n",
      "    Acc(root.right.left)\n",
      "    Acc(root.right.right)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Assignment might fail. There might be insufficient permission to access\n",
      "tree_subtree --------------\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line 6.8\n",
      "\n",
      "### Verified program:\n",
      "def subtree(root: Optional[TreeNode], key: int) -> Optional[TreeNode]:\n",
      "    \"\"\"Returns the subtree rooted at node with the given key if it exists, None otherwise\n",
      "    Permissions to the rest of the tree are leaked\"\"\"\n",
      "    if root is None:\n",
      "        return None\n",
      "    if  root.key == key:\n",
      "        return root\n",
      "    if key < root.key:\n",
      "        return subtree(root.left, key)\n",
      "    return subtree(root.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access root.key. at line\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"evalresults_pretrained.txt\") as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        for k, v in d.items():\n",
    "            print(k, \"--------------\")\n",
    "            print(v)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the programs verify with the pretrained model. In most cases, it has just reproduced the unverified program from the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    \"py39\",\n",
    "    entry_point=\"sagemaker_train.py\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    # transformers_version='4.36',\n",
    "    # pytorch_version='2.1',\n",
    "    # py_version='py310',\n",
    "    image_uri=\"763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-training:1.13-transformers4.26-gpu-py39-cu117-ubuntu20.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-03-06-23-57-59-373\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({'train': train_s3_uri, 'test': eval_s3_uri}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 00:02:38 Starting - Starting the training job\n",
      "2024-03-07 00:02:38 Pending - Preparing the instances for training\n",
      "2024-03-07 00:02:38 Downloading - Downloading the training image\n",
      "2024-03-07 00:02:38 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-03-07 00:03:04,766 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-03-07 00:03:04,787 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-07 00:03:04,796 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-03-07 00:03:04,798 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-03-07 00:03:04,994 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.9 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.37.2\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 53.7 MB/s eta 0:00:00\n",
      "Collecting peft==0.8.2\n",
      "Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 45.1 MB/s eta 0:00:00\n",
      "Collecting trl==0.7.11\n",
      "Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 42.0 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes==0.42.0\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 20.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2.28.2)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 120.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 57.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (1.23.5)\n",
      "Collecting safetensors>=0.4.1\n",
      "Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 100.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.37.2->-r requirements.txt (line 1)) (4.64.1)\n",
      "Collecting accelerate\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 54.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (1.13.1+cu117)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.8.2->-r requirements.txt (line 2)) (5.9.4)\n",
      "Collecting tyro>=0.5.11\n",
      "Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 24.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from trl==0.7.11->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 4)) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r requirements.txt (line 1)) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 kB 43.3 MB/s eta 0:00:00\n",
      "Collecting shtab>=1.5.6\n",
      "Downloading shtab-1.7.0-py3-none-any.whl (14 kB)\n",
      "Collecting docstring-parser>=0.14.1\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.9/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (12.6.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->trl==0.7.11->-r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->trl==0.7.11->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.7.11->-r requirements.txt (line 3)) (1.16.0)\n",
      "Installing collected packages: shtab, safetensors, fsspec, docstring-parser, tyro, huggingface-hub, bitsandbytes, tokenizers, accelerate, transformers, trl, peft\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.1.0\n",
      "Uninstalling fsspec-2023.1.0:\n",
      "Successfully uninstalled fsspec-2023.1.0\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.2\n",
      "Uninstalling tokenizers-0.13.2:\n",
      "Successfully uninstalled tokenizers-0.13.2\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Successfully installed accelerate-0.27.2 bitsandbytes-0.42.0 docstring-parser-0.15 fsspec-2024.2.0 huggingface-hub-0.21.4 peft-0.8.2 safetensors-0.4.2 shtab-1.7.0 tokenizers-0.15.2 transformers-4.37.2 trl-0.7.11 tyro-0.7.3\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-03-07 00:03:18,201 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-03-07 00:03:18,201 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-03-07 00:03:18,241 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-07 00:03:18,272 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-07 00:03:18,302 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-07 00:03:18,313 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-03-06-23-57-59-373\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-06-23-57-59-373/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sagemaker_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sagemaker_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=sagemaker_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=sagemaker_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-06-23-57-59-373/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-03-06-23-57-59-373\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-03-06-23-57-59-373/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_train.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 sagemaker_train.py\n",
      "[2024-03-07 00:03:20.264: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "2024-03-07 00:03:20,268 root         INFO     Using NamedTuple = typing._NamedTuple instead.\n",
      "2024-03-07 00:03:20,398 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [00:43<00:43, 43.11s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [01:08<00:00, 32.82s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [01:08<00:00, 34.37s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:17<00:17, 17.19s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  7.95s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.33s/it]\n",
      "0%|          | 0/4 [00:00<?, ?ba/s]\n",
      "25%|██▌       | 1/4 [00:00<00:01,  2.89ba/s]\n",
      "50%|█████     | 2/4 [00:00<00:00,  2.73ba/s]\n",
      "75%|███████▌  | 3/4 [00:01<00:00,  2.66ba/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.02ba/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.91ba/s]\n",
      "0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.76ba/s]\n",
      "/opt/conda/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "0%|          | 0/456 [00:00<?, ?it/s]\n",
      "[2024-03-07 00:04:57.797: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.37.2 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "INFO:root:Using NamedTuple = typing._NamedTuple instead.\n",
      "[2024-03-07 00:04:57.823 algo-1:65 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-03-07 00:04:57.849 algo-1:65 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2024-03-07 00:04:57.850 algo-1:65 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2024-03-07 00:04:57.850 algo-1:65 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2024-03-07 00:04:57.850 algo-1:65 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2024-03-07 00:04:57.850 algo-1:65 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "0%|          | 1/456 [00:47<5:58:44, 47.31s/it]\n",
      "0%|          | 2/456 [01:33<5:51:30, 46.46s/it]\n",
      "1%|          | 3/456 [02:18<5:47:07, 45.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhuggingface_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/estimator.py:1523\u001b[0m, in \u001b[0;36mEstimatorBase.logs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display the logs for Estimator's training job.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded based\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m    on which instance the log entry is from.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1523\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/session.py:5568\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5548\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5549\u001b[0m \n\u001b[1;32m   5550\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz/hs23/thesis/l4vp/lib/python3.12/site-packages/sagemaker/session.py:7661\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   7659\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 7661\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   7664\u001b[0m     state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the fine tuned model\n",
    "We have added a custom inference.py script to combine the model with the adapter. And archived it in model.tar.gz in code/inference.py as expected by the SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-16-13-38-364/output/model.tar.gz), script artifact (./scripts), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-22-18-35-112/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2024-02-19-22-18-35-112\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2024-02-19-22-19-11-618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "model = huggingface_estimator.create_model(role=role, entry_point=\"inference.py\", source_dir=\"./scripts\")\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.g5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2024-02-19-18-56-49-158\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-inference-2024-02-19-18-56-49-816\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-inference-2024-02-19-18-56-49-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, HuggingFacePredictor\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-eu-west-1-929880127071/huggingface-pytorch-training-2024-02-19-18-03-54-763/model.tar.gz\",  # path to your trained sagemaker model\n",
    "   role=role,\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version=\"1.13\", # pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    "   env={\"HF_TASK\": \"text-generation\"},\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that given a python program, annotates it with appropriate Nagini annotations so that verification succeeds.\n",
      "Nagini is a static verifier for Python. Our aim is to given a statically typed Python program, to come up with appropriate preconditions (e.g. Requires(is_list(head)), Requires(Implies(n is not None, predicate(n)))), postcondition (e.g. Ensures(is_list(Result()))), loop invariants (Invariant(<assertion>)), predicate fold/unfolds (e.g. Fold(is_list(head)) / Unfold(is_list(head))) so that the program verifies correctly. Unfolding(e1, e2) evaluates e2 in the context where predicate e1 is temporarily unfolded.\n",
      "\n",
      "The user will provide Python code and the verification errors. You must add or change the specifications so that the resulting code verifies correctly. Return only the code without any explanation or wrapping.\n",
      "\n",
      "The tree predicate is defined recursively as:\n",
      "@Predicate\n",
      "def tree(n: TreeNode) -> bool:\n",
      "    return (\n",
      "        Acc(n.key)\n",
      "        and Acc(n.left)\n",
      "        and Acc(n.right)\n",
      "        and Implies(n.left is not None, tree(n.left))\n",
      "        and Implies(n.right is not None, tree(n.right))\n",
      "    )\n",
      "\n",
      "### Unverified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    if key < node.key:\n",
      "        if node.left is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.left = new_node\n",
      "        else:\n",
      "            insert(node.left, key)\n",
      "    else:\n",
      "        if node.right is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.right = new_node\n",
      "        else:\n",
      "            insert(node.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "\n",
      "You are an assistant that given a python program, annotates it with appropriate Nagini annotations so that verification succeeds.\n",
      "Nagini is a static verifier for Python. Our aim is to given a statically typed Python program, to come up with appropriate preconditions (e.g. Requires(is_list(head)), Requires(Implies(n is not None, predicate(n)))), postcondition (e.g. Ensures(is_list(Result()))), loop invariants (Invariant(<assertion>)), predicate fold/unfolds (e.g. Fold(is_list(head)) / Unfold(is_list(head))) so that the program verifies correctly. Unfolding(e1, e2) evaluates e2 in the context where predicate e1 is temporarily unfolded.\n",
      "\n",
      "The user will provide Python code and the verification errors. You must add or change the specifications so that the resulting code verifies correctly. Return only the code without any explanation or wrapping.\n",
      "\n",
      "The tree predicate is defined recursively as:\n",
      "@Predicate\n",
      "def tree(n: TreeNode) -> bool:\n",
      "    return (\n",
      "        Acc(n.key)\n",
      "        and Acc(n.left)\n",
      "        and Acc(n.right)\n",
      "        and Implies(n.left is not None, tree(n.left))\n",
      "        and Implies(n.right is not None, tree(n.right))\n",
      "    )\n",
      "\n",
      "### Unverified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    if key < node.key:\n",
      "        if node.left is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.left = new_node\n",
      "        else:\n",
      "            insert(node.left, key)\n",
      "    else:\n",
      "        if node.right is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.right = new_node\n",
      "        else:\n",
      "            insert(node.right, key)\n",
      "\n",
      "\n",
      "### Verification error:\n",
      "Verification failed: Conditional statement might fail. There might be insufficient permission to access node.key. at line 3.7\n",
      "\n",
      "### Verified program:\n",
      "def insert(node: TreeNode, key: int) -> None:\n",
      "    \"\"\"Insert a node with given key into a binary tree.\"\"\"\n",
      "    Requires(tree(node))\n",
      "    Ensures(tree(node))\n",
      "    if key < node.key:\n",
      "        if node.left is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.left = new_node\n",
      "            Fold(tree(new_node))\n",
      "        else:\n",
      "            Unfold(tree(node))\n",
      "            insert(node.left, key)\n",
      "            Fold(tree(node))\n",
      "    else:\n",
      "        if node.right is None:\n",
      "            new_node = TreeNode(key)\n",
      "            node.right\n"
     ]
    }
   ],
   "source": [
    "prompt = evalprompts[14]\n",
    "print(prompt[\"prompt\"])\n",
    "\n",
    "output = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": prompt[\"prompt\"],\n",
    "        \"params\": {\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.7,\n",
    "            \"top_k\": 50,\n",
    "            \"repetition_penalty\": 1,\n",
    "            \n",
    "        },\n",
    "        \"decode_params\": {\n",
    "            \"skip_special_tokens\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-training-2024-02-19-22-18-35-112\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-training-2024-02-19-22-19-11-618\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-training-2024-02-19-22-19-11-618\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l4vp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
